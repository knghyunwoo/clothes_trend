{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c532a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44077cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['short sleeve top', 'long sleeve top', 'short sleeve outwear', 'long sleeve outwear', 'vest', 'sling', 'shorts', 'trousers', 'skirt', 'short sleeve dress', 'long sleeve dress', 'vest dress', 'sling dress']\n"
     ]
    }
   ],
   "source": [
    "# YOLO 설정 파일 Path\n",
    "labelsPath = os.getcwd()+\"\\\\pretrained_yolo\\\\df2.names\" # Hand 라벨\n",
    "weightsPath = os.getcwd()+\"\\\\pretrained_yolo\\\\yolov3-df2_15000.weights\" # 가중치\n",
    "configPath = os.getcwd()+\"\\\\pretrained_yolo\\\\yolov3-df2.cfg\" # 모델 구성\n",
    "\n",
    "# YOLO 라벨(hand) 호출\n",
    "YOLO_LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "\n",
    "# YOLO 모델 호출\n",
    "yolo_net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "\n",
    "# YOLO 출력층 설정\n",
    "layer_names = yolo_net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in yolo_net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(YOLO_LABELS), 3))\n",
    "\n",
    "print(YOLO_LABELS)\n",
    "\n",
    "frame_id = 0\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42295f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_area(image, image_area, color):\n",
    "    result = 0\n",
    "    kernal = np.ones((5, 5), 'uint8')\n",
    "\n",
    "    # Convert BGR color space to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define masks for each color\n",
    "    mask = cv2.inRange(hsv_image,\n",
    "        LOWER_HSV[color], UPPER_HSV[color])\n",
    "\n",
    "    # Create contour\n",
    "    mask = cv2.dilate(mask, kernal)\n",
    "    cv2.bitwise_and(image, image, mask=mask)\n",
    "    contours, _ = cv2.findContours(\n",
    "        mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Track color\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if (area > image_area * 0.001):\n",
    "            _, _, w, h = cv2.boundingRect(contour)\n",
    "            result += w*h\n",
    "\n",
    "    return result\n",
    "\n",
    "def detect_color(image_path, leftup=None, rightdown=None):\n",
    "    # Get image\n",
    "    image = image_path\n",
    "    if leftup != None and rightdown != None:\n",
    "        image = image[leftup[1]: rightdown[1], leftup[0]: rightdown[0]]\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "    image_area = height * width\n",
    "\n",
    "    # Calcuate color areas\n",
    "    white_area = calculate_area(image, image_area, 'white')\n",
    "    red_area = calculate_area(image, image_area, 'red')\n",
    "    green_area = calculate_area(image, image_area, 'green')\n",
    "    blue_area = calculate_area(image, image_area, 'blue')\n",
    "    yellow_area = calculate_area(image, image_area, 'yellow')\n",
    "    orange_area = calculate_area(image, image_area, 'orange')\n",
    "    black_area = calculate_area(image, image_area, 'black')\n",
    "    grey_area = calculate_area(image, image_area, 'grey')\n",
    "    brown_area = calculate_area(image, image_area, 'brown')\n",
    "    navy_area = calculate_area(image, image_area, 'navy')\n",
    "    purple_area = calculate_area(image, image_area, 'purple')\n",
    "    pink_area = calculate_area(image, image_area, 'pink')\n",
    "\n",
    "    areas = {'white': white_area, 'grey': grey_area, 'black': black_area, 'brown': brown_area,\n",
    "             'blue': blue_area, 'navy': navy_area, 'purple': purple_area, 'green': green_area, 'red': red_area,\n",
    "             'orange': orange_area, 'yellow': yellow_area, 'pink': pink_area}\n",
    "    \n",
    "    return max(areas, key=lambda x : areas[x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b276d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color boundaries\n",
    "LOWER_HSV = {\n",
    "    'red': np.array([145, 100, 20], np.uint8),\n",
    "    \"orange\": np.array([10, 100, 100], np.uint8),\n",
    "    'yellow': np.array([17, 100, 20], np.uint8),\n",
    "    'green': np.array([60, 100, 20], np.uint8),\n",
    "    'blue': np.array([90, 100, 20], np.uint8),\n",
    "    \"navy\": np.array([110, 100, 20], np.uint8),\n",
    "    \"purple\": np.array([125, 100, 20], np.uint8),\n",
    "    \"pink\": np.array([0, 70, 20], np.uint8),\n",
    "    \"black\": np.array([0, 0, 0], np.uint8), \n",
    "    \"white\": np.array([0, 0, 80], np.uint8),\n",
    "    \"grey\": np.array([0, 0, 150], np.uint8), \n",
    "    \"brown\": np.array([10, 100, 20], np.uint8), \n",
    "}\n",
    "\n",
    "UPPER_HSV = {\n",
    "    'red': np.array([180, 255, 255], np.uint8),\n",
    "    \"orange\": np.array([20, 255, 255], np.uint8),\n",
    "    'yellow': np.array([35, 255, 255], np.uint8),\n",
    "    'green': np.array([90, 255, 255], np.uint8),\n",
    "    'blue': np.array([110, 255, 255], np.uint8),\n",
    "    \"navy\": np.array([125, 255, 255], np.uint8),\n",
    "    \"purple\": np.array([135, 255, 255], np.uint8),\n",
    "    \"pink\": np.array([6, 255, 250], np.uint8),\n",
    "    \"black\": np.array([180, 60, 80], np.uint8), \n",
    "    \"white\": np.array([120, 40, 177], np.uint8),\n",
    "    \"grey\": np.array([40, 30, 170], np.uint8), \n",
    "    \"brown\": np.array([20, 255, 200], np.uint8) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0a3b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "model_name = 'efficientnet-b0'  # b5\n",
    "\n",
    "image_size = EfficientNet.get_image_size(model_name)\n",
    "men_model = EfficientNet.from_pretrained(model_name, num_classes=4)\n",
    "women_model = EfficientNet.from_pretrained(model_name, num_classes=4)\n",
    "MEN_PATH = \"./pretrained_efficientnet/men_style_discriminator.pt\"\n",
    "WOMEN_PATH = \"./pretrained_efficientnet/women_style_discriminator.pt\"\n",
    "device = torch.device('cpu') \n",
    "\n",
    "men_model.load_state_dict(torch.load(MEN_PATH, map_location=device))\n",
    "women_model.load_state_dict(torch.load(WOMEN_PATH, map_location=device))\n",
    "\n",
    "tfms = transforms.Compose([transforms.Resize(224), transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
    "\n",
    "class_names = [\"Casual\", \"Hip\", \"Office\", \"Sports\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17abca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_feature(image_path, model):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    img_height, img_width, channels = img.shape\n",
    "\n",
    "    # Detecting objects\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416),  swapRB=True, crop=False) #mean=(0,0,0)\n",
    "\n",
    "    yolo_net.setInput(blob)\n",
    "    outs = yolo_net.forward(output_layers)\n",
    "\n",
    "\n",
    "    # Showing informations on the screen\n",
    "    class_ids = []\n",
    "    confidences = [] \n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.01: #0.01 \n",
    "\n",
    "                # Object detected\n",
    "                center_x = int(detection[0] * img_width)\n",
    "                center_y = int(detection[1] * img_height)\n",
    "                width = int(detection[2] * img_width)\n",
    "                height = int(detection[3] * img_height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                xx = int(center_x - width / 2)\n",
    "                yy = int(center_y - height / 2)\n",
    "\n",
    "                boxes.append([xx, yy, width, height])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "\n",
    "    draw_img = img.copy()\n",
    "    count=0\n",
    "    max_temp = 0\n",
    "\n",
    "    ## NMS 처리하기\n",
    "    conf_threshold = 0.1\n",
    "    nms_threshold = 0.4\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "    feature_list = []\n",
    "    \n",
    "\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():\n",
    "            each_feature = []\n",
    "            box = boxes[i]\n",
    "            if box[1] < 0: box[1] = 0\n",
    "            if box[0] < 0: box[0] = 0\n",
    "            left = box[0]\n",
    "            top = box[1]\n",
    "            width = box[2]\n",
    "            height = box[3]\n",
    "            if width*height > max_temp:\n",
    "                max_temp = width*height\n",
    "                caption = \"{}: {:.4f}\".format(YOLO_LABELS[class_ids[i]], confidences[i])\n",
    "                cv2.rectangle(draw_img, (int(left), int(top)), (int(left+width), int(top+height)), color=(0,255,0), thickness=2)\n",
    "\n",
    "                crop_img = img[top:top + height, left:left + width]\n",
    "                color = detect_color(crop_img)\n",
    "                clothes_type = YOLO_LABELS[class_ids[i]]\n",
    "                \n",
    "                cv2.imwrite(\"crop_img.jpg\", crop_img)\n",
    "                crop_img = tfms(Image.open(\"crop_img.jpg\")).unsqueeze(0)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(crop_img)\n",
    "\n",
    "                for idx in torch.topk(outputs, k=1).indices.squeeze(0).tolist():\n",
    "                    prob = torch.softmax(outputs, dim=1)[0, idx].item()\n",
    "                    \n",
    "                style = class_names[idx]\n",
    "    \n",
    "                each_feature.append(color)\n",
    "                each_feature.append(style)\n",
    "                each_feature.append(clothes_type)\n",
    "                each_feature.append(color + \" \" + style)\n",
    "                each_feature.append(color + \" \" + clothes_type)\n",
    "                each_feature.append(style + \" \" + clothes_type)\n",
    "                each_feature.append(color + \" \" + style + \" \" + clothes_type)\n",
    "                \n",
    "\n",
    "                count += 1\n",
    "                feature_list.append(each_feature)\n",
    "            else: \n",
    "                continue\n",
    "\n",
    "\n",
    "#     img_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n",
    "#     plt.figure(figsize=(12, 12))\n",
    "#     plt.imshow(img_rgb)\n",
    "    \n",
    "    return feature_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05deb4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['black',\n",
       "  'Hip',\n",
       "  'shorts',\n",
       "  'black Hip',\n",
       "  'black shorts',\n",
       "  'Hip shorts',\n",
       "  'black Hip shorts']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_feature(f\"./crawled_images/shein_men_crawled\\\\best1.jpg\", men_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9bb714e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "women_list = []\n",
    "men_list = []\n",
    "\n",
    "\n",
    "for i in range(1, 1201): \n",
    "    try:\n",
    "        men_list.extend(detect_feature(f\"./crawled_images/shein_men_crawled\\\\best{i}.jpg\", men_model))\n",
    "        men_list.extend(detect_feature(f\"./crawled_images/wconcept_men_crawled\\\\best{i}.jpg\", men_model))\n",
    "        women_list.extend(detect_feature(f\"./crawled_images/shein_women_crawled\\\\best{i}.jpg\", women_model))\n",
    "        women_list.extend(detect_feature(f\"./crawled_images/wconcept_women_crawled\\\\best{i}.jpg\", women_model))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f494f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2324\n",
      "2563\n"
     ]
    }
   ],
   "source": [
    "print(len(men_list))\n",
    "print(len(women_list))\n",
    "# print(men_list)\n",
    "# print(women_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e16f232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       color style                 type color+style                 color+type  \\\n",
      "0     black   Hip               shorts   black Hip               black shorts   \n",
      "1      grey   Hip                skirt    grey Hip                 grey skirt   \n",
      "2     white   Hip  long sleeve outwear   white Hip  white long sleeve outwear   \n",
      "3     white   Hip     short sleeve top   white Hip     white short sleeve top   \n",
      "4     white   Hip     short sleeve top   white Hip     white short sleeve top   \n",
      "...     ...   ...                  ...         ...                        ...   \n",
      "2319  white   Hip             trousers   white Hip             white trousers   \n",
      "2320  white   Hip  long sleeve outwear   white Hip  white long sleeve outwear   \n",
      "2321  black   Hip               shorts   black Hip               black shorts   \n",
      "2322  black   Hip               shorts   black Hip               black shorts   \n",
      "2323  brown   Hip               shorts   brown Hip               brown shorts   \n",
      "\n",
      "                   style+type               color+style+type  \n",
      "0                  Hip shorts               black Hip shorts  \n",
      "1                   Hip skirt                 grey Hip skirt  \n",
      "2     Hip long sleeve outwear  white Hip long sleeve outwear  \n",
      "3        Hip short sleeve top     white Hip short sleeve top  \n",
      "4        Hip short sleeve top     white Hip short sleeve top  \n",
      "...                       ...                            ...  \n",
      "2319             Hip trousers             white Hip trousers  \n",
      "2320  Hip long sleeve outwear  white Hip long sleeve outwear  \n",
      "2321               Hip shorts               black Hip shorts  \n",
      "2322               Hip shorts               black Hip shorts  \n",
      "2323               Hip shorts               brown Hip shorts  \n",
      "\n",
      "[2324 rows x 7 columns]>\n",
      "<bound method NDFrame.head of       color   style              type   color+style              color+type  \\\n",
      "0     white  Office             skirt  white Office             white skirt   \n",
      "1     white  Office  short sleeve top  white Office  white short sleeve top   \n",
      "2     white  Office          trousers  white Office          white trousers   \n",
      "3     white  Office   long sleeve top  white Office   white long sleeve top   \n",
      "4      grey  Sports             skirt   grey Sports              grey skirt   \n",
      "...     ...     ...               ...           ...                     ...   \n",
      "2558   pink  Office             skirt   pink Office              pink skirt   \n",
      "2559  black  Office          trousers  black Office          black trousers   \n",
      "2560  white  Sports   long sleeve top  white Sports   white long sleeve top   \n",
      "2561  white  Office          trousers  white Office          white trousers   \n",
      "2562   blue  Sports  short sleeve top   blue Sports   blue short sleeve top   \n",
      "\n",
      "                   style+type               color+style+type  \n",
      "0                Office skirt             white Office skirt  \n",
      "1     Office short sleeve top  white Office short sleeve top  \n",
      "2             Office trousers          white Office trousers  \n",
      "3      Office long sleeve top   white Office long sleeve top  \n",
      "4                Sports skirt              grey Sports skirt  \n",
      "...                       ...                            ...  \n",
      "2558             Office skirt              pink Office skirt  \n",
      "2559          Office trousers          black Office trousers  \n",
      "2560   Sports long sleeve top   white Sports long sleeve top  \n",
      "2561          Office trousers          white Office trousers  \n",
      "2562  Sports short sleeve top   blue Sports short sleeve top  \n",
      "\n",
      "[2563 rows x 7 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "men_df = pd.DataFrame(men_list)\n",
    "men_df.columns = [\"color\", \"style\", \"type\", \"color+style\", \"color+type\", \"style+type\", \"color+style+type\"]\n",
    "print(men_df.head)\n",
    "men_df.to_excel('men.xlsx', index=False)\n",
    "\n",
    "women_df = pd.DataFrame(women_list)\n",
    "women_df.columns = [\"color\", \"style\", \"type\", \"color+style\", \"color+type\", \"style+type\", \"color+style+type\"]\n",
    "print(women_df.head)\n",
    "women_df.to_excel('women.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
